# EDA & Network Analysis
#########################

### packages

from networkx.algorithms import average_clustering
from itertools import combinations as comb
from community import community_louvain
from collections import Counter
import networkx as nx

### count the frenquency of words and roots/words

words_list = []
for i,l in enumerate(data_words):
    for w in l:
        words_list.append(w)
        
freq = Counter(words_list)
words_freq = {k: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True)}
print(words_freq)

roots_list = []
for i,l in enumerate(data_roots):
    for w in l:
        roots_list.append(w)

freq = Counter(roots_list)
roots_freq = {k: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True)}
print(roots_freq)

### create a list with words combinations (nodes)  

combinations = []
for article in words_list:
    words = list(set(article)) 
    combination1 = list(comb(words, 2))  
    combination2.append(combination1)   

x = len(combination2)                              
combination3 = combination2[0]                      

for i in range(1,x):                               
    combination3 = combination3 + combination2[i]  
combination_reference = list(set(combination3)) 

combination4 = []
for word_pair in combination_reference:
    z = combination3.count(word_pair) 
    combination4.append([word_pair,z])

### select only combinations with more than 3 relations

combinations = []
for pair in combination4:
    weight = pair[1] 
    if weight >= 4:
        combinations.append([pair[0], weight])

### Include weight in the tupla of combinations and a list 'edges' 

edges = []
for combination in combinations:
    words = combination[0]
    weight = combination[1]
    edge = words + (weight, )
    edges.append(edge)
    
### create a weighted graph

graph = nx.Graph()

graph.add_weighted_edges_from(edges)

### convert graph into gephi (.graphml)

nx.write_graphml(graph, 'cowords.graphml')

### measure nodes, relations, and density 

print('Number of nodes', len(graph.nodes))

print('Number of relations', len(graph.edges))

print('Density', round(nx.density(graph), 2))

### create dict with words' degree

degree_dict = dict(graph.degree(graph.nodes(), weight='weight')) 
sorted_degree = sorted(degree_dict.items(), key=itemgetter(1), reverse=True) 
sorted_degree

### create a dict with betweenness

betweenness_dict = nx.betweenness_centrality(graph, weight='weight')
sorted_betweenness = sorted(betweenness_dict.items(), key=itemgetter(1), reverse=True)
sorted_betweenness

### create the clusters

communities = community_louvain.best_partition(graph, weight='weight') # Calcula 
sorted_communities = sorted(communities.items(), key=itemgetter(1), reverse=True)
sorted_communities

### create a subgraph with nodes of the same clusters 

class6 = []
class5 = []
class4 = []
class3 = []
class2 = []
class1 = []
class0 = []

for n in graph.nodes():
    if graph.node[n]['modularity'] == 6:      
        class6.append(n)
    elif graph.node[n]['modularity'] == 5:      
        class5.append(n)
    elif graph.node[n]['modularity'] == 4:      
        class4.append(n)
    elif graph.node[n]['modularity'] == 3:      
        class3.append(n)
    elif graph.node[n]['modularity'] == 2:      
        class2.append(n)
    elif graph.node[n]['modularity'] == 1:      
        class1.append(n)
    elif graph.node[n]['modularity'] == 0:      
        class0.append(n)
    else:
        pass

graph6 = graph.subgraph(class6)
graph5 = graph.subgraph(class5)
graph4 = graph.subgraph(class4)
graph3 = graph.subgraph(class3)
graph2 = graph.subgraph(class2)
graph1 = graph.subgraph(class1)
graph0 = graph.subgraph(class0)
